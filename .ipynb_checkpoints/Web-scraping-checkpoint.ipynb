{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b0911f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "years = list(range(2021, 2026))\n",
    "dfs = []\n",
    "\n",
    "for year in years:\n",
    "    url = f\"https://www.basketball-reference.com/leagues/NBA_{year}_per_game.html\"\n",
    "    df = pd.read_html(url)[0]\n",
    "    df = df[df[\"Player\"] != \"Player\"]\n",
    "    lebron = df[df[\"Player\"] == \"LeBron James\"].copy()\n",
    "    lebron[\"Season\"] = f\"{year-1}-{str(year)[-2:]}\"\n",
    "    dfs.append(lebron)\n",
    "\n",
    "# Combine all seasons\n",
    "all_lebron = pd.concat(dfs)\n",
    "all_lebron.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Convert PTS column to numeric\n",
    "all_lebron[\"PTS\"] = pd.to_numeric(all_lebron[\"PTS\"], errors=\"coerce\")\n",
    "\n",
    "# Create output folder\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "\n",
    "# Plot: Points Per Game over seasons\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(all_lebron[\"Season\"], all_lebron[\"PTS\"], marker=\"o\", linewidth=2)\n",
    "plt.title(\"LeBron James Points Per Game by Season (2020–2024)\")\n",
    "plt.xlabel(\"Season\")\n",
    "plt.ylabel(\"Points Per Game (PPG)\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"output/lebron_ppg.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fda67fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Player Names\n",
    "players = [\"LeBron James\",\"Kevin Durant\",\"Stephen Curry\"]\n",
    "years = list(range(2021, 2026))\n",
    "\n",
    "all_data = []\n",
    "\n",
    "for year in years:\n",
    "    url = f\"https://www.basketball-reference.com/leagues/NBA_{year}_per_game.html\"\n",
    "    df = pd.read_html(url)[0]\n",
    "    df = df[df[\"Player\"] != \"Player\"]  # 去除多余表头\n",
    "\n",
    "    for player in players:\n",
    "        player_rows = df[df[\"Player\"] == player].copy()\n",
    "        if not player_rows.empty:\n",
    "            if \"2TM\" in player_rows[\"Team\"].values:\n",
    "                pdata = player_rows[player_rows[\"Team\"] == \"2TM\"].copy()\n",
    "            else:\n",
    "                pdata = player_rows.iloc[[0]].copy()  # 如果没有多队，只取第一行\n",
    "            pdata[\"Season\"] = f\"{year-1}-{str(year)[-2:]}\"\n",
    "            pdata[\"Player\"] = player\n",
    "            all_data.append(pdata)\n",
    "\n",
    "\n",
    "# 合并所有球员数据\n",
    "df_all = pd.concat(all_data)\n",
    "df_all.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# 转为数字\n",
    "df_all[\"PTS\"] = pd.to_numeric(df_all[\"PTS\"], errors=\"coerce\")\n",
    "\n",
    "# 创建输出目录\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "\n",
    "# 画图\n",
    "plt.figure(figsize=(9,6))\n",
    "\n",
    "for player in players:\n",
    "    sub = df_all[df_all[\"Player\"] == player]\n",
    "    plt.plot(sub[\"Season\"], sub[\"PTS\"], marker=\"o\", label=player)\n",
    "\n",
    "plt.title(\"Points Per Game (2021–2025)\")\n",
    "plt.xlabel(\"Season\")\n",
    "plt.ylabel(\"Points Per Game (PPG)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"output/ppg_comparison.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa098bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Player Names\n",
    "players = [\"LeBron James\",\"Kevin Durant\",\"Stephen Curry\",\"Nikola Jokić\"]\n",
    "years = list(range(2021, 2026))\n",
    "\n",
    "all_data = []\n",
    "\n",
    "for year in years:\n",
    "    url = f\"https://www.basketball-reference.com/leagues/NBA_{year}_advanced.html\"\n",
    "    df = pd.read_html(url)[0]\n",
    "    df = df[df[\"Player\"] != \"Player\"]  # 去除多余表头\n",
    "\n",
    "    for player in players:\n",
    "        player_rows = df[df[\"Player\"] == player].copy()\n",
    "        if not player_rows.empty:\n",
    "            if \"2TM\" in player_rows[\"Team\"].values:\n",
    "                pdata = player_rows[player_rows[\"Team\"] == \"2TM\"].copy()\n",
    "            else:\n",
    "                pdata = player_rows.iloc[[0]].copy()  # 如果没有多队，只取第一行\n",
    "            pdata[\"Season\"] = f\"{year-1}-{str(year)[-2:]}\"\n",
    "            pdata[\"Player\"] = player\n",
    "            all_data.append(pdata)\n",
    "\n",
    "\n",
    "# 合并所有球员数据\n",
    "df_all = pd.concat(all_data)\n",
    "df_all.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# 转为数字\n",
    "df_all[\"BPM\"] = pd.to_numeric(df_all[\"BPM\"], errors=\"coerce\")\n",
    "\n",
    "# 创建输出目录\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "\n",
    "# 画图\n",
    "plt.figure(figsize=(9,6))\n",
    "\n",
    "for player in players:\n",
    "    sub = df_all[df_all[\"Player\"] == player]\n",
    "    plt.plot(sub[\"Season\"], sub[\"BPM\"], marker=\"o\", label=player)\n",
    "\n",
    "plt.title(\"Advanced Stats (2021–2025)\")\n",
    "plt.xlabel(\"Season\")\n",
    "plt.ylabel(\"BPM\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"output/BPM_comparison.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "957f66cb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2010...\n",
      "Processing 2011...\n",
      "Processing 2012...\n",
      "Processing 2013...\n",
      "Processing 2014...\n",
      "Processing 2015...\n",
      "Processing 2016...\n",
      "Processing 2017...\n",
      "Processing 2018...\n",
      "Processing 2019...\n",
      "Processing 2020...\n",
      "Processing 2021...\n",
      "Processing 2022...\n",
      "Processing 2023...\n",
      "Processing 2024...\n",
      "Processing 2025...\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 429: Too Many Requests",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# --- 1. 抓 per_game 数据 ---\u001b[39;00m\n\u001b[0;32m     14\u001b[0m url_pg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.basketball-reference.com/leagues/NBA_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_per_game.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 15\u001b[0m df_pg \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_html(url_pg)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     16\u001b[0m df_pg \u001b[38;5;241m=\u001b[39m df_pg[df_pg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlayer\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlayer\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# --- 2. 抓 advanced 数据 ---\u001b[39;00m\n",
      "File \u001b[1;32mD:\\ANACONDA\\Lib\\site-packages\\pandas\\io\\html.py:1212\u001b[0m, in \u001b[0;36mread_html\u001b[1;34m(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, thousands, encoding, decimal, converters, na_values, keep_default_na, displayed_only, extract_links, dtype_backend)\u001b[0m\n\u001b[0;32m   1208\u001b[0m check_dtype_backend(dtype_backend)\n\u001b[0;32m   1210\u001b[0m io \u001b[38;5;241m=\u001b[39m stringify_path(io)\n\u001b[1;32m-> 1212\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _parse(\n\u001b[0;32m   1213\u001b[0m     flavor\u001b[38;5;241m=\u001b[39mflavor,\n\u001b[0;32m   1214\u001b[0m     io\u001b[38;5;241m=\u001b[39mio,\n\u001b[0;32m   1215\u001b[0m     match\u001b[38;5;241m=\u001b[39mmatch,\n\u001b[0;32m   1216\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   1217\u001b[0m     index_col\u001b[38;5;241m=\u001b[39mindex_col,\n\u001b[0;32m   1218\u001b[0m     skiprows\u001b[38;5;241m=\u001b[39mskiprows,\n\u001b[0;32m   1219\u001b[0m     parse_dates\u001b[38;5;241m=\u001b[39mparse_dates,\n\u001b[0;32m   1220\u001b[0m     thousands\u001b[38;5;241m=\u001b[39mthousands,\n\u001b[0;32m   1221\u001b[0m     attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1222\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m   1223\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   1224\u001b[0m     converters\u001b[38;5;241m=\u001b[39mconverters,\n\u001b[0;32m   1225\u001b[0m     na_values\u001b[38;5;241m=\u001b[39mna_values,\n\u001b[0;32m   1226\u001b[0m     keep_default_na\u001b[38;5;241m=\u001b[39mkeep_default_na,\n\u001b[0;32m   1227\u001b[0m     displayed_only\u001b[38;5;241m=\u001b[39mdisplayed_only,\n\u001b[0;32m   1228\u001b[0m     extract_links\u001b[38;5;241m=\u001b[39mextract_links,\n\u001b[0;32m   1229\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1230\u001b[0m )\n",
      "File \u001b[1;32mD:\\ANACONDA\\Lib\\site-packages\\pandas\\io\\html.py:981\u001b[0m, in \u001b[0;36m_parse\u001b[1;34m(flavor, io, match, attrs, encoding, displayed_only, extract_links, **kwargs)\u001b[0m\n\u001b[0;32m    978\u001b[0m p \u001b[38;5;241m=\u001b[39m parser(io, compiled_match, attrs, encoding, displayed_only, extract_links)\n\u001b[0;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 981\u001b[0m     tables \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mparse_tables()\n\u001b[0;32m    982\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m caught:\n\u001b[0;32m    983\u001b[0m     \u001b[38;5;66;03m# if `io` is an io-like object, check if it's seekable\u001b[39;00m\n\u001b[0;32m    984\u001b[0m     \u001b[38;5;66;03m# and try to rewind it before trying the next parser\u001b[39;00m\n\u001b[0;32m    985\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(io, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseekable\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m io\u001b[38;5;241m.\u001b[39mseekable():\n",
      "File \u001b[1;32mD:\\ANACONDA\\Lib\\site-packages\\pandas\\io\\html.py:257\u001b[0m, in \u001b[0;36m_HtmlFrameParser.parse_tables\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_tables\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    250\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;124;03m    Parse and return all tables from the DOM.\u001b[39;00m\n\u001b[0;32m    252\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;124;03m    list of parsed (header, body, footer) tuples from tables.\u001b[39;00m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 257\u001b[0m     tables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_tables(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_doc(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmatch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrs)\n\u001b[0;32m    258\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_thead_tbody_tfoot(table) \u001b[38;5;28;01mfor\u001b[39;00m table \u001b[38;5;129;01min\u001b[39;00m tables)\n",
      "File \u001b[1;32mD:\\ANACONDA\\Lib\\site-packages\\pandas\\io\\html.py:816\u001b[0m, in \u001b[0;36m_LxmlFrameParser._build_doc\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    814\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    815\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 816\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    818\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(r, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext_content\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mD:\\ANACONDA\\Lib\\site-packages\\pandas\\io\\html.py:797\u001b[0m, in \u001b[0;36m_LxmlFrameParser._build_doc\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    795\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_url(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mio):\n\u001b[1;32m--> 797\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m urlopen(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mio) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    798\u001b[0m             r \u001b[38;5;241m=\u001b[39m parse(f, parser\u001b[38;5;241m=\u001b[39mparser)\n\u001b[0;32m    799\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    800\u001b[0m         \u001b[38;5;66;03m# try to parse the input in the simplest way\u001b[39;00m\n",
      "File \u001b[1;32mD:\\ANACONDA\\Lib\\site-packages\\pandas\\io\\common.py:270\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;124;03mLazy-import wrapper for stdlib urlopen, as that imports a big chunk of\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;124;03mthe stdlib.\u001b[39;00m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrequest\u001b[39;00m\n\u001b[1;32m--> 270\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39murlopen(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\ANACONDA\\Lib\\urllib\\request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m opener\u001b[38;5;241m.\u001b[39mopen(url, data, timeout)\n",
      "File \u001b[1;32mD:\\ANACONDA\\Lib\\urllib\\request.py:525\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[0;32m    524\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[1;32m--> 525\u001b[0m     response \u001b[38;5;241m=\u001b[39m meth(req, response)\n\u001b[0;32m    527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mD:\\ANACONDA\\Lib\\urllib\\request.py:634\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[1;32m--> 634\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39merror(\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp\u001b[39m\u001b[38;5;124m'\u001b[39m, request, response, code, msg, hdrs)\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mD:\\ANACONDA\\Lib\\urllib\\request.py:563\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[0;32m    562\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[1;32m--> 563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_chain(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[1;32mD:\\ANACONDA\\Lib\\urllib\\request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[0;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mD:\\ANACONDA\\Lib\\urllib\\request.py:643\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[1;32m--> 643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 429: Too Many Requests"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 球员名单与年份范围\n",
    "players = [\"LeBron James\", \"Kevin Durant\", \"Stephen Curry\"]\n",
    "years = list(range(2016, 2026))\n",
    "\n",
    "all_data = []\n",
    "\n",
    "for year in years:\n",
    "    print(f\"Processing {year}...\")\n",
    "\n",
    "    # --- 1. 抓 per_game 数据 ---\n",
    "    url_pg = f\"https://www.basketball-reference.com/leagues/NBA_{year}_per_game.html\"\n",
    "    df_pg = pd.read_html(url_pg)[0]\n",
    "    df_pg = df_pg[df_pg[\"Player\"] != \"Player\"]\n",
    "\n",
    "    # --- 2. 抓 advanced 数据 ---\n",
    "    url_adv = f\"https://www.basketball-reference.com/leagues/NBA_{year}_advanced.html\"\n",
    "    df_adv = pd.read_html(url_adv)[0]\n",
    "    df_adv = df_adv[df_adv[\"Player\"] != \"Player\"]\n",
    "\n",
    "    for player in players:\n",
    "        # per_game 筛选\n",
    "        pg_rows = df_pg[df_pg[\"Player\"] == player].copy()\n",
    "        if pg_rows.empty:\n",
    "            continue\n",
    "        if \"2TM\" in pg_rows[\"Team\"].values:\n",
    "            pg = pg_rows[pg_rows[\"Team\"] == \"2TM\"].copy()\n",
    "        else:\n",
    "            pg = pg_rows.iloc[[0]].copy()\n",
    "\n",
    "        # advanced 筛选\n",
    "        adv_rows = df_adv[df_adv[\"Player\"] == player].copy()\n",
    "        if adv_rows.empty:\n",
    "            continue\n",
    "        if \"2TM\" in adv_rows[\"Team\"].values:\n",
    "            adv = adv_rows[adv_rows[\"Team\"] == \"2TM\"].copy()\n",
    "        else:\n",
    "            adv = adv_rows.iloc[[0]].copy()\n",
    "\n",
    "        # 合并两部分\n",
    "        merged = pd.DataFrame({\n",
    "            \"Player\": [player],\n",
    "            \"Season\": [f\"{year-1}-{str(year)[-2:]}\"],\n",
    "            \"Team\": pg[\"Team\"].values[0],\n",
    "            \"PTS\": pd.to_numeric(pg[\"PTS\"].values[0], errors=\"coerce\"),\n",
    "            \"TRB\": pd.to_numeric(pg[\"TRB\"].values[0], errors=\"coerce\"),\n",
    "            \"AST\": pd.to_numeric(pg[\"AST\"].values[0], errors=\"coerce\"),\n",
    "            \"STL\": pd.to_numeric(pg[\"STL\"].values[0], errors=\"coerce\"),\n",
    "            \"BLK\": pd.to_numeric(pg[\"BLK\"].values[0], errors=\"coerce\"),\n",
    "            \"TOV\": pd.to_numeric(pg[\"TOV\"].values[0], errors=\"coerce\"),\n",
    "            \"BPM\": pd.to_numeric(adv[\"BPM\"].values[0], errors=\"coerce\"),\n",
    "            \"PER\": pd.to_numeric(adv[\"PER\"].values[0], errors=\"coerce\"),\n",
    "            \"WS\": pd.to_numeric(adv[\"WS\"].values[0], errors=\"coerce\")\n",
    "        })\n",
    "\n",
    "        all_data.append(merged)\n",
    "\n",
    "# 合并所有数据并导出\n",
    "df_all = pd.concat(all_data)\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "df_all.to_csv(\"output/nba_selected_stats.csv\", index=False)\n",
    "print(\"✅ Saved to output/nba_selected_stats.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eff26639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2016...\n",
      "Processing 2017...\n",
      "Processing 2018...\n",
      "Processing 2019...\n",
      "Processing 2020...\n",
      "Processing 2021...\n",
      "Processing 2022...\n",
      "Processing 2023...\n",
      "Processing 2024...\n",
      "Processing 2025...\n",
      "✅ Saved to output/nba_selected_stats.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 设置球员名单和年份范围\n",
    "players = [\n",
    "    # Superstar\n",
    "    \"LeBron James\", \"Kevin Durant\", \"Stephen Curry\", \"Nikola Jokic\",\n",
    "    \"Giannis Antetokounmpo\", \"Joel Embiid\", \"Kawhi Leonard\", \"James Harden\",\n",
    "    \"Russell Westbrook\",\n",
    "\n",
    "    # All-Star\n",
    "    \"Jayson Tatum\", \"Luka Doncic\", \"Anthony Davis\", \"Devin Booker\",\n",
    "    \"Damian Lillard\", \"Jimmy Butler\", \"Kyrie Irving\", \"Paul George\", \"Chris Paul\",\n",
    "\n",
    "    # Great players\n",
    "    \"Shai Gilgeous-Alexander\", \"Ja Morant\", \"Zion Williamson\", \"LaMelo Ball\",\n",
    "    \"Anthony Edwards\", \"Tyrese Haliburton\", \"Cade Cunningham\", \"Jalen Green\",\n",
    "    \"Scottie Barnes\", \"Victor Wembanyama\", \"Chet Holmgren\", \"Klay Thompson\",\n",
    "    \"Bradley Beal\", \"DeMar DeRozan\", \"Mike Conley\", \"Julius Randle\",\n",
    "    \n",
    "    \"Jaylen Brown\", \"Jrue Holiday\", \"Bam Adebayo\", \"Andrew Wiggins\",\n",
    "    \"Kristaps Porzingis\", \"Deandre Ayton\", \"CJ McCollum\", \"Michael Porter Jr.\",\n",
    "    \"Desmond Bane\", \"RJ Barrett\", \"Austin Reaves\", \"Derrick White\",\"Donovan Mitchell\",\n",
    "\n",
    "    # Good players\n",
    "    \"De'Aaron Fox\", \"Domantas Sabonis\", \"Karl-Anthony Towns\", \"Brandon Ingram\",\n",
    "    \"Pascal Siakam\", \"Fred VanVleet\", \"Draymond Green\", \"Brook Lopez\",\n",
    "    \"Mikal Bridges\", \"Aaron Gordon\", \"Tyrese Maxey\", \"Darius Garland\",\n",
    "\n",
    "    # Progress Player \n",
    "    \"Jalen Brunson\", \"Franz Wagner\", \"Alperen Sengun\", \"Josh Giddey\",\n",
    "    \"Bennedict Mathurin\", \"Keegan Murray\", \"Immanuel Quickley\", \"Cam Thomas\"\n",
    "]\n",
    "\n",
    "years = list(range(2016, 2026))\n",
    "\n",
    "# 设置输出目录\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "\n",
    "# 自定义请求头（伪装浏览器）\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"\n",
    "}\n",
    "\n",
    "# 定义一个辅助函数：获取网页表格\n",
    "def get_table(url):\n",
    "    try:\n",
    "        response = requests.get(url, headers=HEADERS)\n",
    "        response.raise_for_status()\n",
    "        return pd.read_html(response.text)[0]\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error fetching {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "# 开始抓取数据\n",
    "all_data = []\n",
    "\n",
    "for year in years:\n",
    "    print(f\"Processing {year}...\")\n",
    "    \n",
    "    # 每年之间加随机延时\n",
    "    time.sleep(random.uniform(3, 6))\n",
    "\n",
    "    # 1. per_game\n",
    "    url_pg = f\"https://www.basketball-reference.com/leagues/NBA_{year}_per_game.html\"\n",
    "    df_pg = get_table(url_pg)\n",
    "    if df_pg is None:\n",
    "        continue\n",
    "    df_pg = df_pg[df_pg[\"Player\"] != \"Player\"]\n",
    "\n",
    "    # 2. advanced\n",
    "    url_adv = f\"https://www.basketball-reference.com/leagues/NBA_{year}_advanced.html\"\n",
    "    df_adv = get_table(url_adv)\n",
    "    if df_adv is None:\n",
    "        continue\n",
    "    df_adv = df_adv[df_adv[\"Player\"] != \"Player\"]\n",
    "\n",
    "    for player in players:\n",
    "        # per_game\n",
    "        pg_rows = df_pg[df_pg[\"Player\"] == player].copy()\n",
    "        if pg_rows.empty:\n",
    "            continue\n",
    "        pg = pg_rows[pg_rows[\"Team\"] == \"2TM\"] if \"2TM\" in pg_rows[\"Team\"].values else pg_rows.iloc[[0]]\n",
    "\n",
    "        # advanced\n",
    "        adv_rows = df_adv[df_adv[\"Player\"] == player].copy()\n",
    "        if adv_rows.empty:\n",
    "            continue\n",
    "        adv = adv_rows[adv_rows[\"Team\"] == \"2TM\"] if \"2TM\" in adv_rows[\"Team\"].values else adv_rows.iloc[[0]]\n",
    "\n",
    "        # 合并为一行\n",
    "        merged = pd.DataFrame({\n",
    "            \"Player\": [player],\n",
    "            \"Season\": [f\"{year-1}-{str(year)[-2:]}\"],\n",
    "            \"Team\": pg[\"Team\"].values[0],\n",
    "    \n",
    "        # 基础数据\n",
    "            \"PTS\": pd.to_numeric(pg[\"PTS\"].values[0], errors=\"coerce\"),\n",
    "            \"TRB\": pd.to_numeric(pg[\"TRB\"].values[0], errors=\"coerce\"),\n",
    "            \"AST\": pd.to_numeric(pg[\"AST\"].values[0], errors=\"coerce\"),\n",
    "            \"STL\": pd.to_numeric(pg[\"STL\"].values[0], errors=\"coerce\"),\n",
    "            \"BLK\": pd.to_numeric(pg[\"BLK\"].values[0], errors=\"coerce\"),\n",
    "            \"TOV\": pd.to_numeric(pg[\"TOV\"].values[0], errors=\"coerce\"),\n",
    "            \"FT\": pd.to_numeric(pg[\"FT\"].values[0], errors=\"coerce\"),\n",
    "\n",
    "        # 命中率类（来自 per_game）\n",
    "            \"FG%\": pd.to_numeric(pg[\"FG%\"].values[0], errors=\"coerce\"),\n",
    "            \"3P%\": pd.to_numeric(pg[\"3P%\"].values[0], errors=\"coerce\"),\n",
    "            \"2P%\": pd.to_numeric(pg[\"2P%\"].values[0], errors=\"coerce\"),\n",
    "            \"FT%\": pd.to_numeric(pg[\"FT%\"].values[0], errors=\"coerce\"),\n",
    "\n",
    "        # 高阶数据（来自 advanced）\n",
    "            \"TS%\": pd.to_numeric(adv[\"TS%\"].values[0], errors=\"coerce\"),\n",
    "            \"BPM\": pd.to_numeric(adv[\"BPM\"].values[0], errors=\"coerce\"),\n",
    "            \"OBPM\": pd.to_numeric(adv[\"OBPM\"].values[0], errors=\"coerce\"),\n",
    "            \"DBPM\": pd.to_numeric(adv[\"DBPM\"].values[0], errors=\"coerce\"),\n",
    "            \"PER\": pd.to_numeric(adv[\"PER\"].values[0], errors=\"coerce\"),\n",
    "            \"WS\": pd.to_numeric(adv[\"WS\"].values[0], errors=\"coerce\")\n",
    "        })\n",
    "\n",
    "\n",
    "        all_data.append(merged)\n",
    "\n",
    "# 合并所有数据并导出\n",
    "if all_data:\n",
    "    df_all = pd.concat(all_data)\n",
    "    df_all.to_csv(\"output/nba_selected_stats.csv\", index=False)\n",
    "    print(\"✅ Saved to output/nba_selected_stats.csv\")\n",
    "else:\n",
    "    print(\"❌ No data collected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08ca305d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2016...\n",
      "Processing 2017...\n",
      "Processing 2018...\n",
      "Processing 2019...\n",
      "Processing 2020...\n",
      "Processing 2021...\n",
      "Processing 2022...\n",
      "Processing 2023...\n",
      "Processing 2024...\n",
      "Processing 2025...\n",
      "✅ Saved to output/nba_selected_stats.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import unicodedata\n",
    "\n",
    "def strip_accents(text):\n",
    "    \"\"\"统一去除重音，避免匹配失败\"\"\"\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', text)\n",
    "                   if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "# 设置球员名单和年份范围\n",
    "players = [\n",
    "    # Superstar\n",
    "    \"LeBron James\", \"Kevin Durant\", \"Stephen Curry\", \"Nikola Jokić\",\n",
    "    \"Giannis Antetokounmpo\", \"Joel Embiid\", \"Kawhi Leonard\", \"James Harden\",\n",
    "    \"Russell Westbrook\",\n",
    "\n",
    "    # All-Star\n",
    "    \"Jayson Tatum\", \"Luka Doncic\", \"Anthony Davis\", \"Devin Booker\",\n",
    "    \"Damian Lillard\", \"Jimmy Butler\", \"Kyrie Irving\", \"Paul George\", \"Chris Paul\",\n",
    "\n",
    "    # Great players\n",
    "    \"Shai Gilgeous-Alexander\", \"Ja Morant\", \"Zion Williamson\", \"LaMelo Ball\",\n",
    "    \"Anthony Edwards\", \"Tyrese Haliburton\", \"Cade Cunningham\", \"Jalen Green\",\n",
    "    \"Scottie Barnes\", \"Victor Wembanyama\", \"Chet Holmgren\", \"Klay Thompson\",\n",
    "    \"Bradley Beal\", \"DeMar DeRozan\", \"Mike Conley\", \"Julius Randle\",\n",
    "    \n",
    "    \"Jaylen Brown\", \"Jrue Holiday\", \"Bam Adebayo\", \"Andrew Wiggins\",\n",
    "    \"Kristaps Porzingis\", \"Deandre Ayton\", \"CJ McCollum\", \"Michael Porter Jr.\",\n",
    "    \"Desmond Bane\", \"RJ Barrett\", \"Austin Reaves\", \"Derrick White\",\"Donovan Mitchell\",\n",
    "\n",
    "    # Good players\n",
    "    \"De'Aaron Fox\", \"Domantas Sabonis\", \"Karl-Anthony Towns\", \"Brandon Ingram\",\n",
    "    \"Pascal Siakam\", \"Fred VanVleet\", \"Draymond Green\", \"Brook Lopez\",\n",
    "    \"Mikal Bridges\", \"Aaron Gordon\", \"Tyrese Maxey\", \"Darius Garland\",\n",
    "\n",
    "    # Progress Player \n",
    "    \"Jalen Brunson\", \"Franz Wagner\", \"Alperen Sengun\", \"Josh Giddey\",\n",
    "    \"Bennedict Mathurin\", \"Keegan Murray\", \"Immanuel Quickley\", \"Cam Thomas\"\n",
    "]\n",
    "\n",
    "years = list(range(2016, 2026))\n",
    "\n",
    "# 设置输出目录\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "\n",
    "# 自定义请求头（伪装浏览器）\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"\n",
    "}\n",
    "\n",
    "# 定义一个辅助函数：获取网页表格\n",
    "def get_table(url):\n",
    "    try:\n",
    "        response = requests.get(url, headers=HEADERS)\n",
    "        response.raise_for_status()\n",
    "        return pd.read_html(response.text)[0]\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error fetching {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "# 开始抓取数据\n",
    "all_data = []\n",
    "\n",
    "for year in years:\n",
    "    print(f\"Processing {year}...\")\n",
    "    \n",
    "    # 每年之间加随机延时\n",
    "    time.sleep(random.uniform(3, 6))\n",
    "\n",
    "    # 1. per_game\n",
    "    url_pg = f\"https://www.basketball-reference.com/leagues/NBA_{year}_per_game.html\"\n",
    "    df_pg = get_table(url_pg)\n",
    "    if df_pg is None:\n",
    "        continue\n",
    "    df_pg = df_pg[df_pg[\"Player\"] != \"Player\"]\n",
    "\n",
    "    # 2. advanced\n",
    "    url_adv = f\"https://www.basketball-reference.com/leagues/NBA_{year}_advanced.html\"\n",
    "    df_adv = get_table(url_adv)\n",
    "    if df_adv is None:\n",
    "        continue\n",
    "    df_adv = df_adv[df_adv[\"Player\"] != \"Player\"]\n",
    "\n",
    "    for player in players:\n",
    "        # per_game\n",
    "        pg_rows = df_pg[df_pg[\"Player\"].apply(strip_accents) == strip_accents(player)].copy()\n",
    "        if pg_rows.empty:\n",
    "            continue\n",
    "        pg = pg_rows[pg_rows[\"Team\"] == \"2TM\"] if \"2TM\" in pg_rows[\"Team\"].values else pg_rows.iloc[[0]]\n",
    "\n",
    "        # advanced\n",
    "        adv_rows = df_adv[df_adv[\"Player\"].apply(strip_accents) == strip_accents(player)].copy()\n",
    "        if adv_rows.empty:\n",
    "            continue\n",
    "        adv = adv_rows[adv_rows[\"Team\"] == \"2TM\"] if \"2TM\" in adv_rows[\"Team\"].values else adv_rows.iloc[[0]]\n",
    "\n",
    "        # 合并为一行\n",
    "        merged = pd.DataFrame({\n",
    "            \"Player\": [player],\n",
    "            \"Season\": [f\"{year-1}-{str(year)[-2:]}\"],\n",
    "            \"Team\": pg[\"Team\"].values[0],\n",
    "    \n",
    "        # 基础数据\n",
    "            \"PTS\": pd.to_numeric(pg[\"PTS\"].values[0], errors=\"coerce\"),\n",
    "            \"TRB\": pd.to_numeric(pg[\"TRB\"].values[0], errors=\"coerce\"),\n",
    "            \"AST\": pd.to_numeric(pg[\"AST\"].values[0], errors=\"coerce\"),\n",
    "            \"STL\": pd.to_numeric(pg[\"STL\"].values[0], errors=\"coerce\"),\n",
    "            \"BLK\": pd.to_numeric(pg[\"BLK\"].values[0], errors=\"coerce\"),\n",
    "            \"TOV\": pd.to_numeric(pg[\"TOV\"].values[0], errors=\"coerce\"),\n",
    "            \"FT\": pd.to_numeric(pg[\"FT\"].values[0], errors=\"coerce\"),\n",
    "\n",
    "        # 命中率类（来自 per_game）\n",
    "            \"FG%\": pd.to_numeric(pg[\"FG%\"].values[0], errors=\"coerce\"),\n",
    "            \"3P%\": pd.to_numeric(pg[\"3P%\"].values[0], errors=\"coerce\"),\n",
    "            \"2P%\": pd.to_numeric(pg[\"2P%\"].values[0], errors=\"coerce\"),\n",
    "            \"FT%\": pd.to_numeric(pg[\"FT%\"].values[0], errors=\"coerce\"),\n",
    "\n",
    "        # 高阶数据（来自 advanced）\n",
    "            \"TS%\": pd.to_numeric(adv[\"TS%\"].values[0], errors=\"coerce\"),\n",
    "            \"BPM\": pd.to_numeric(adv[\"BPM\"].values[0], errors=\"coerce\"),\n",
    "            \"OBPM\": pd.to_numeric(adv[\"OBPM\"].values[0], errors=\"coerce\"),\n",
    "            \"DBPM\": pd.to_numeric(adv[\"DBPM\"].values[0], errors=\"coerce\"),\n",
    "            \"PER\": pd.to_numeric(adv[\"PER\"].values[0], errors=\"coerce\"),\n",
    "            \"WS\": pd.to_numeric(adv[\"WS\"].values[0], errors=\"coerce\")\n",
    "        })\n",
    "\n",
    "\n",
    "        all_data.append(merged)\n",
    "\n",
    "# 合并所有数据并导出\n",
    "if all_data:\n",
    "    df_all = pd.concat(all_data)\n",
    "    df_all.to_csv(\"output/nba_selected_stats.csv\", index=False)\n",
    "    print(\"✅ Saved to output/nba_selected_stats.csv\")\n",
    "else:\n",
    "    print(\"❌ No data collected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd76d044",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
